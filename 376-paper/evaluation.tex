TODO Julie. NOTE: Use APA format.
Relevance, Likability (and Concrete/abstract)

We evaluated the system on three related metrics: the likability of the generated color palettes, how topic-relevant the palettes were perceived to be, and how the colors in the palette affect understanding of the data they represent. For all three metrics, the algorithmically generated palettes were compared against a randomly generated palette, and one generated by experts. For the likability and understanding metrics, the random palette was chosen from the set of palettes generated for other topics by our system. This was to ensure that only the relevance, not the base quality of the colors was considered. For all topics tested, we limited the number of specific items represented in the palette to four. This also allowed us to compare the algorithmically and randomly generated palettes to the randomly generated palettes. We ran a small laboratory study of X participants recruited through school mailing lists, in addition to a large-scale crowdsourced study on Amazon's Mechanical Turk. 

\subsection{Likability}
To measure likability, the automatically, expert, and randomly generated color palettes for a given topic are presented in a random order. Participants rate each palette on a seven-point Likert scale based on how much they like each palette for a given topic. 

\subsection{Relevance}
For relevance, an association task is used: given a topic (e.g "US Politics") and one of the topic terms (e.g. "Democrat"), the participant chooses which color, among a set of displayed swatches, is relevant to it.

\subsection{Understanding}
For understanding, users will be shown differently-colored infographics, and participants will be timed while they answer conceptual questions related to the infographic. Since the three metrics may interact strongly, they will be studied in a within-subjects design.